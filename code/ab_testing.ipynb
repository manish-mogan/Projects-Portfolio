{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9417db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/ab_test_experiment.csv')\n",
    "if not path.exists():\n",
    "    raise FileNotFoundError(f\"Missing {path}. Run: python ../scripts/generate_demo_datasets.py\")\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e2fe5",
   "metadata": {},
   "source": [
    "## SRM check\n",
    "A sample ratio mismatch can invalidate results if assignment is broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d28274",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['variant'].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square goodness-of-fit against 50/50\n",
    "obs = counts.reindex(['control','treatment']).values\n",
    "exp = np.array([obs.sum()/2, obs.sum()/2])\n",
    "chi2, p_srm = stats.chisquare(f_obs=obs, f_exp=exp)\n",
    "print('SRM p-value:', p_srm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea439932",
   "metadata": {},
   "source": [
    "## Conversion uplift\n",
    "We estimate the difference in conversion rates and compute a (Wald) confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby('variant').agg(n=('user_id','count'), conv=('converted','mean'), rpu=('revenue','mean'))\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = summary.loc['control']\n",
    "t = summary.loc['treatment']\n",
    "\n",
    "p1, n1 = c['conv'], c['n']\n",
    "p2, n2 = t['conv'], t['n']\n",
    "\n",
    "diff = p2 - p1\n",
    "se = np.sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\n",
    "z = 1.96\n",
    "ci = (diff - z*se, diff + z*se)\n",
    "\n",
    "# Two-proportion z-test\n",
    "p_pool = (p1*n1 + p2*n2)/(n1+n2)\n",
    "se_pool = np.sqrt(p_pool*(1-p_pool)*(1/n1 + 1/n2))\n",
    "z_stat = diff / se_pool\n",
    "p_val = 2*(1 - stats.norm.cdf(abs(z_stat)))\n",
    "\n",
    "print(f'Control conv: {p1:.3%}  Treatment conv: {p2:.3%}')\n",
    "print(f'Uplift (pp): {diff*100:.2f}  95% CI: [{ci[0]*100:.2f}, {ci[1]*100:.2f}]')\n",
    "print('p-value:', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775015f4",
   "metadata": {},
   "source": [
    "## Power + MDE (planning)\n",
    "Before you start an experiment, it helps to estimate how much traffic you need, or what **minimum detectable effect (MDE)** you can realistically detect.\n",
    "\n",
    "The calculations below use a normal approximation for a two-sample proportion test (two-sided). They’re a good planning baseline, not a substitute for experiment design review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b312893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple planning helpers for two-proportion tests\n",
    "from math import ceil\n",
    "from scipy.stats import norm\n",
    "\n",
    "def mde_from_n(p_baseline: float, n_per_group: int, alpha: float = 0.05, power: float = 0.8) -> float:\n",
    "    \"\"\"Approx MDE (absolute) for a two-sided two-proportion z-test.\"\"\"\n",
    "    if not (0 < p_baseline < 1):\n",
    "        raise ValueError(\"p_baseline must be in (0,1)\")\n",
    "    if n_per_group <= 0:\n",
    "        raise ValueError(\"n_per_group must be > 0\")\n",
    "    z_alpha = norm.ppf(1 - alpha / 2)\n",
    "    z_beta = norm.ppf(power)\n",
    "    se = np.sqrt(2 * p_baseline * (1 - p_baseline) / n_per_group)\n",
    "    return float((z_alpha + z_beta) * se)\n",
    "\n",
    "def required_n_two_proportions(\n",
    "    p_baseline: float,\n",
    "    mde_abs: float,\n",
    "    alpha: float = 0.05,\n",
    "    power: float = 0.8,\n",
    "    ratio_treatment_to_control: float = 1.0,\n",
    ") -> tuple[int, int]:\n",
    "    \"\"\"Approx required sample sizes (n_control, n_treatment) given baseline and absolute MDE.\"\"\"\n",
    "    p1_plan = float(p_baseline)\n",
    "    p2_plan = float(p_baseline + mde_abs)\n",
    "    if not (0 < p1_plan < 1 and 0 < p2_plan < 1):\n",
    "        raise ValueError(\"baseline and baseline+mde must be in (0,1)\")\n",
    "    if ratio_treatment_to_control <= 0:\n",
    "        raise ValueError(\"ratio_treatment_to_control must be > 0\")\n",
    "\n",
    "    z_alpha = norm.ppf(1 - alpha / 2)\n",
    "    z_beta = norm.ppf(power)\n",
    "    p_bar = (p1_plan + p2_plan) / 2\n",
    "    numerator = (z_alpha * np.sqrt(2 * p_bar * (1 - p_bar))) + (z_beta * np.sqrt(p1_plan * (1 - p1_plan) + p2_plan * (1 - p2_plan)))\n",
    "    n_control = ceil((numerator / (p2_plan - p1_plan)) ** 2)\n",
    "    n_treatment = ceil(n_control * ratio_treatment_to_control)\n",
    "    return int(n_control), int(n_treatment)\n",
    "\n",
    "baseline = float(p1)\n",
    "n_per_group = int(min(n1, n2))\n",
    "mde_80 = mde_from_n(baseline, n_per_group, alpha=0.05, power=0.8)\n",
    "\n",
    "print(f\"Baseline conversion (control): {baseline:.3%}\")\n",
    "print(f\"Current n per group (min): {n_per_group:,}\")\n",
    "print(f\"Approx MDE @ 80% power, alpha=0.05: {mde_80*100:.2f} percentage points\")\n",
    "\n",
    "# Example: how many users per group for a 0.50pp lift?\n",
    "target_mde_pp = 0.50\n",
    "n_c_req, n_t_req = required_n_two_proportions(baseline, mde_abs=target_mde_pp/100, alpha=0.05, power=0.8)\n",
    "print(f\"Required n per group for {target_mde_pp:.2f}pp MDE: control={n_c_req:,} treatment={n_t_req:,} (total={n_c_req+n_t_req:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c541fcf8",
   "metadata": {},
   "source": [
    "## Variance reduction (optional): CUPED\n",
    "If you have a **pre-experiment** version of a metric (e.g., pre-period revenue), you can apply CUPED to reduce variance and increase power.\n",
    "\n",
    "This demo dataset may not include a pre-period metric, so the cell below will **skip** unless it detects a suitable column.\n",
    "```\n",
    "CUPED:  $Y_{cuped} = Y - \\theta (X - \\bar{X})$  where  $\\theta = \\frac{\\mathrm{Cov}(Y, X)}{\\mathrm{Var}(X)}$\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUPED demo (runs only if a plausible pre-period column exists)\n",
    "possible_pre_cols = [c for c in df.columns if c.lower() in {'pre_revenue', 'revenue_pre', 'pre_period_revenue', 'pre_metric'}]\n",
    "pre_col = possible_pre_cols[0] if possible_pre_cols else None\n",
    "post_col = 'revenue' if 'revenue' in df.columns else None\n",
    "\n",
    "if pre_col is None or post_col is None:\n",
    "    print('Skipping CUPED: no pre-period metric column found (expected one of: pre_revenue, revenue_pre, pre_period_revenue, pre_metric).')\n",
    "else:\n",
    "    tmp = df[['variant', pre_col, post_col]].dropna()\n",
    "    x = tmp[pre_col].astype(float)\n",
    "    y = tmp[post_col].astype(float)\n",
    "    theta = np.cov(y, x, ddof=1)[0, 1] / np.var(x, ddof=1)\n",
    "    y_cuped = y - theta * (x - x.mean())\n",
    "    tmp = tmp.assign(revenue_cuped=y_cuped)\n",
    "\n",
    "    cuped_summary = tmp.groupby('variant').agg(n=('variant','size'), mean=('revenue_cuped','mean'), std=('revenue_cuped','std'))\n",
    "    print('CUPED using pre column:', pre_col)\n",
    "    display(cuped_summary)\n",
    "\n",
    "    # Compare standard errors (roughly) vs raw revenue\n",
    "    raw_summary = tmp.groupby('variant')[post_col].agg(['count','mean','std']).rename(columns={'count':'n'})\n",
    "    se_raw = raw_summary['std'] / np.sqrt(raw_summary['n'])\n",
    "    se_cuped = cuped_summary['std'] / np.sqrt(cuped_summary['n'])\n",
    "    compare = pd.DataFrame({'se_raw_revenue': se_raw, 'se_cuped_revenue': se_cuped})\n",
    "    display(compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddaa65",
   "metadata": {},
   "source": [
    "## Multiple comparisons (practical note)\n",
    "If you slice results into many segments (or test many metrics), your chance of a false positive increases. A simple, conservative adjustment is **Bonferroni**: use $\\alpha/k$ if you run $k$ hypothesis tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: adjust alpha for multiple tests\n",
    "k = 5  # e.g., 5 segments or metrics you plan to evaluate\n",
    "alpha = 0.05\n",
    "alpha_bonf = alpha / k\n",
    "print(f\"If you run k={k} tests, Bonferroni-adjusted alpha = {alpha_bonf:.4f}\")\n",
    "\n",
    "# If you're doing many segment tests, consider controlling FDR (e.g., Benjamini–Hochberg) instead of strict Bonferroni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dbe1cc",
   "metadata": {},
   "source": [
    "## Revenue per user (secondary metric)\n",
    "A quick comparison of average revenue per user (including zeros for non-converters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d770591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(data=summary.reset_index(), x='variant', y='rpu')\n",
    "plt.title('Revenue per user')\n",
    "plt.ylabel('RPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b745e",
   "metadata": {},
   "source": [
    "## Segment check (device)\n",
    "Useful for communicating *where* impact is concentrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = (df.groupby(['device','variant'])['converted'].mean().reset_index())\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(data=seg, x='device', y='converted', hue='variant')\n",
    "plt.title('Conversion rate by device')\n",
    "plt.ylabel('Conversion rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
